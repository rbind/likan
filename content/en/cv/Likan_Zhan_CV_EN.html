---
title: "Curriculum Vitae"
disable_comments: yes
date: '2016-01-22'
lastmod: "2019-07-18"
output:
  pdf_document:
    includes:
      in_header: ~/Documents/ADMIN/Website/LaTex/Preamble_Blogdown_CV.tex
    latex_engine: xelatex
    md_extensions: -autolink_bare_uris +hard_line_breaks
    keep_tex: false
  html_document:
    df_print: paged
  word_document: default
geometry: margin=1in
pdf: /en/cv/Likan_Zhan_CV_EN.pdf
type: cv
urlcolor: blue
fontsize: 12pt
---



<div id="likan-zhan" class="section level1">
<h1>Likan ZHAN</h1>
<ul>
<li><i class="far fa-map-marker-alt"></i>   15, Xueyuan Road, Haidian District, Beijing 100083, China</li>
<li><i class="fas fa-phone"></i>   + 86 10 8230 3468</li>
<li><i class="far fa-envelope"></i>   <a href="mailto:zhanlikan@hotmail.com" class="email">zhanlikan@hotmail.com</a></li>
<li><i class="fas fa-globe"></i>   <a href="https://likan.info" class="uri">https://likan.info</a></li>
<li>Last update: 2019-07-18</li>
</ul>
<div id="academic-appointment" class="section level2">
<h2>Academic appointment</h2>
<ul>
<li><p>2019.07 ~ Now, Associate professor,<br>
School of Communication Science,<br>
Beijing Language and Culture University, Beijing, China</p></li>
<li><p>2014.10 ~ 2019.06, Assistant professor,<br>
MEG Laboratory for Brain Sciences, <br>
Institute for Speech Pathology and the Brain Science,<br>
Beijing Language and Culture University, Beijing, China</p></li>
</ul>
</div>
<div id="education" class="section level2">
<h2>Education</h2>
<ul>
<li><p>2010.10 ~ 2014.09, Ph.D. Cognitive Science, <br>
Macquarie University, Sydney, Australia</p></li>
<li><p>2007.09 ~ 2010.07, M.E. Cognitive Psychology, <br>
Beijing Language and Culture University, Beijing, China</p></li>
<li><p>2000.09 ~ 2004.07, B.A. Teaching Chinese as a Second Language, <br>
Beijing Language and Culture University, Beijing, China</p></li>
</ul>
</div>
<div id="teaching-experience" class="section level2">
<h2>Teaching experience</h2>
<ul>
<li><p>2019 ~ Now. Experimental Psychology, <br>
Undergraduates, 4 hours per week, 68 hours in total</p></li>
<li><p>2017 ~ Now. Statistics for the Behavioral Sciences, <br>
Undergraduates and post-graduates, 2 hours per week, 34 hours in total</p></li>
<li><p>2016 ~ Now. R for Modeling and Visualizing Data, <br>
Post-graduates and PhD candicates, 4 hours per week, 68 hours in total</p></li>
<li><p>2015 ~ Now. Introduction to Cognitive Neuroscience, <br>
Post-graduates and PhD candicates, 2 hours per week, 34 hours in total</p></li>
<li><p>2015 ~ Now. Foundations of Scientific Research, <br>
Under-graduates, 3 hours per week, 54 hours in total</p></li>
<li><p>2015 Fall. General Psychology, <br>
Under-graduates, 3 hours per week, 54 hours in total</p></li>
</ul>
</div>
<div id="professional-skills" class="section level2">
<h2>Professional skills</h2>
<ol style="list-style-type: decimal">
<li>Experiment techniques</li>
</ol>
<ul>
<li>Test stimuli: <a href="https://ctan.org/pkg/pgf?lang=en">PGF</a> package in <a href="https://www.latex-project.org">LaTeX</a>, <a href="https://imagemagick.org">ImageMagick</a> and its implementation in R <a href="https://cran.r-project.org/web/packages/magick/index.html">magick</a>, <a href="https://www.omnigroup.com/omnigraffle/">OmniGraffle</a> (Proprietary), and <a href="https://www.pixelmator.com">Pixelmator</a> (Proprietary) for image creating and editting; <a href="http://www.fon.hum.uva.nl/praat/">praat</a>, R packages <a href="https://cran.r-project.org/web/packages/tuneR/index.html">tuneR</a> and <a href="https://cran.r-project.org/package=seewave">seewave</a>, and <a href="https://www.adobe.com/products/audition.html">Adobe Audition</a> (Proprietary) for audio editting and processing; <a href="https://www.blender.org">blender</a> and <a href="https://www.autodesk.com/products/maya/overview">Autodesk Maya</a> (Proprietary) for video and 3d modeling; <a href="https://ffmpeg.org">ffmpeg</a> for audio and video format converting;</li>
<li>Experiments building: <a href="http://www.psychopy.org">Psychopy</a> under <a href="https://www.python.org">Python</a>, <a href="http://psychtoolbox.org">Psychtoolbox</a> under <a href="https://www.mathworks.com/products/matlab.html">Matlab</a>, <a href="https://www.pstnet.com/eprime.cfm">E-prime</a> (Proprietary), <a href="https://www.neurobs.com/presentation">Presentation</a> (Proprietary), and <a href="https://www.sr-research.com/experiment-builder/">Experiment Builder</a> (Proprietary);</li>
<li>Eye-tracker: Advanced experience in using <a href="https://www.sr-research.com">Eyelink II/1000 plus</a> for conducting experiments, <a href="https://www.sr-research.com/experiment-builder/">Experiment Builder</a> for experiment building, and <a href="https://www.sr-research.com/data-viewer/">Data Viewer</a> for data prepossing;</li>
<li>E/MEG: In charge of establishing the first Child MEG lab in China; familiar with Yokogawa MEG system for equipment maintenance and MEG data acquisition, as well as <a href="http://www.besa.de">BESA</a>, <a href="http://www.fieldtriptoolbox.org">fieldtrip</a>, and <a href="https://github.com/neurodebian/spm12">SPM12</a> for data processing.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Data processing</li>
</ol>
<ul>
<li>R: Moderate experience in using <a href="https://www.r-project.org">R</a> for statistical modeling and data visualization, especially: <a href="http://r-datatable.com">data.table</a>, <a href="https://cran.r-project.org/web/packages/dplyr/index.html">dplyr</a>, and <a href="https://cran.r-project.org/web/packages/tidyr/index.html">tidyr</a> for data preprossing; <a href="https://stat.ethz.ch/R-manual/R-devel/library/graphics/html/00Index.html">graphics</a>, <a href="https://cran.r-project.org/package=lattice">lattice</a>, and <a href="http://ggplot2.tidyverse.org">ggplot2</a> for data visualization; <a href="https://cran.r-project.org/web/packages/car/index.html">car</a>, <a href="https://github.com/lme4/lme4">lme4</a>, and <a href="https://cran.r-project.org/web/packages/gam/index.html">gam</a> for computational modeling; create the R package <a href="https://github.com/likanzhan/acqr">acqr</a> for teaching statistics and illustrating data visualization;</li>
<li>Julia: Recently started to use <a href="https://julialang.org">julia</a> for computational modeling, especially the <a href="https://github.com/dmbates/MixedModels.jl">MixedModels</a> package, because of the speed limitations of R.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Other</li>
</ol>
<ul>
<li>Markup languages: <a href="https://www.latex-project.org">LaTeX</a>, <a href="https://daringfireball.net/projects/markdown/">markdown</a>, and <a href="https://rmarkdown.rstudio.com">R markdown</a> for typesetting; <a href="https://pandoc.org">Pandoc</a> for converting files from one markup format into another;</li>
<li>Personal website: Use <a href="https://gohugo.io">hugo</a> under <a href="https://golang.org">Go</a> language and the R package <a href="https://github.com/rstudio/blogdown">blogdown</a> to build my personal website <a href="https://likan.info">https://likan.info</a>.</li>
</ul>
</div>
<div id="grants-projects-and-awards" class="section level2">
<h2>Grants, projects, and awards</h2>
<ol style="list-style-type: decimal">
<li>Grants</li>
</ol>
<ul>
<li><p><strong>Zhan, L.</strong>, Zhou, P., Zhang, L., &amp; Crain, S. (2019 - 2023). The Acquisition and Online Processing of Irrealis in Mandarin Chinese. <em>The National Social Science Fund of China</em>. [Grant No. 19BYY087]. (¥200,000). Role: Principle Investigator.</p></li>
<li><p><strong>Zhan, L.</strong>, Qu, Y., Xu, J., Xiao, Y., &amp; Li, N. (2019 - 2020). The eye movements pattern and neural oscitation markers of predictive processing in language comprehension. <em>The Fundamental Research Funds for the Central Universities</em>. [Grant No. 19YJ080002]. (¥70,000). Role: Principle Investigator.</p></li>
<li><p><strong>Zhan, L.</strong>, Shi, F., Gao, L., &amp; Zhang, L. (2019 - 2020). The online prrocessing and acquisition of lexical tone in Mandarin Chinese. <em>The Fundamental Research Funds for the Central Universities</em>. [Grant No. 18YBT15]. (¥70,000). Role: Principle Investigator.</p></li>
<li><p>Shi, D., et al. (2019 - 2023). The study of Mandarin Chinese from a generative perspective and The innovation of grammar theories in the new era. <em>The Major Program of the National Natural Social Science Foundation of China</em>. [Grant No. 18ZDA291]. (¥800,000). Role: Co-Investigator.</p></li>
<li><p>Si, F., et al. (2018 - 2023). Language acquisition and language cognition under the perspective of syntactic cartography. <em>The Fundamental Research Funds for the Central Universities</em>. [Grant No. 18ZDJ06]. (¥300,000). Role: Co-Investigator.</p></li>
<li><p><strong>Zhan, L.</strong> (2015 - 2016). Experimental explorations of possible world semantics. <em>The Fundamental Research Funds for the Central Universities</em>. [Grant No. 15YBB29]. (¥20,000). Role: Principle Investigator.</p></li>
<li><p><strong>Zhan, L.</strong> (2015 - 2016). Introduction to psychology and the scientific research. <em>The Funds Supporting the Growth of the New Teachers</em>. [Grant No. FD201530]. (¥7,000). Role: Principle Investigator.</p></li>
<li><p><strong>Zhan, L.</strong>, Shi, F., Gao, L., &amp; Zhang, L. (2015 - 2016). The Processing and acquisition of tone in Mandarin Chinese. <em>The Fundamental Research Funds for the Central Universities</em>. [Grant No. 15YJ050003]. (¥70,000). Role: Principle Investigator.</p></li>
<li><p><strong>Zhan, L.</strong> (2010 - 2014). The interpretation of conditionals in natural language. <em>Cognitive Science Postgraduate Research Grant of Macquarie University</em>. ($10,570). Role: Principle Investigator.</p></li>
<li><p><strong>Zhan, L.</strong> (20103). The hypothetical property of conditionals in natural language. <em>Macquarie University Postgraduate Research Fund</em>. ($4,684). Role: Principle Investigator.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Projects</li>
</ol>
<ul>
<li><p>Zhang, L., et al. (2018 - Now). The psychological and brain development of atypical developing adolensences. <em>The Program of WuTong Inovations Platforms</em>. Role: Co-Investigator.</p></li>
<li><p>Chen, M., et al. (2019 - Now). The study of Chinese as a second language acquisition and second language teaching (The JunCai Group). <em>The Program of Establishing First-Class Disciplines in BLCU</em>. Role: Co-Investigator.</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Awards</li>
</ol>
<ul>
<li><p>2013.11. The Paula Menyuk Travel Award for the 38th Boston University Conference on Language Development. ($300).</p></li>
<li><p>2013.04. The Travel Award for the 26th Annual CUNY Sentence Processing Conference. ($350).</p></li>
</ul>
</div>
<div id="professional-activities" class="section level2">
<h2>Professional activities</h2>
<ol style="list-style-type: decimal">
<li>Organization of international meetings</li>
</ol>
<ul>
<li>Academic Advisory Committee, The 24th annual conference of the International Association of Chinese Linguistics (<a href="http://iacl24.blcu.edu.cn">IACL-24</a>), Beijing Language and Culture University, Beijing, China.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Ad-hoc reviews</li>
</ol>
<ul>
<li>Scientific Reports. (2019);</li>
<li>Journal of visualized experiments. (2018);</li>
<li>Language Teaching and Linguistic Studies. (In Chinese, 2016).</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Clinical licenses</li>
</ol>
<ul>
<li><p>Licensed Examiner of Wechsler Preschool and Primary Scale of Intelligence 4th Edition (WPPSI-VI) Chinese Version.</p></li>
<li><p>Licensed Examiner of Adaptive Behavior Assessment System 2nd Edition (ABAS-II) Chinese Version.</p></li>
</ul>
</div>
<div id="publications" class="section level2">
<h2>Publications</h2>
<ol style="list-style-type: decimal">
<li>Book</li>
</ol>
<ul>
<li><strong>Zhan, L.</strong> (2015). <em>The Interpretation of Conditionals in Natural Language</em>. Saarbrucken, Germany: Lap Lambert Academic Publishing.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Periodicals</li>
</ol>
<ul>
<li><p>Zhou, P., <strong>Zhan, L.</strong>, &amp; Ma, H. (2018). Predictive language processing in preschool children with Autism Spectrum Disorder: An eye-tracking study. <em>Journal of Psycholinguistic Research</em>. <a href="doi:10.1007/s10936-018-9612-5" class="uri">doi:10.1007/s10936-018-9612-5</a> <a href="https://publications.likan.info/Periodicals/JPsycholinguistRes2018.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong> (2018). Using eye movements recorded in the visual world paradigm to explore the online processing of spoken language. <em>Journal of Visualized Experiments, 140</em>, e58086. doi: 10.3791/58086 <a href="https://publications.likan.info/Periodicals/jove-protocol-58086.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p>Zhou, P., Ma, W., <strong>Zhan, L.</strong>, &amp; Ma, H (2018). Using the visual world paradigm to study sentence comprehension in Mandarin-speaking children with autism. <em>Journal of Visualized Experiments, 140</em>, e58452. doi: 10.3791/58452 <a href="https://publications.likan.info/Periodicals/jove-protocol-58452.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong>, Zhou, P., &amp; Crain, S. (2018). Using the visual-world paradigm to explore the meaning of conditionals in natural language. <em>Language, Cognition and Neuroscience, 33</em>(8), 1049-1062. doi: 10.1080/23273798.2018.1448935 <a href="https://publications.likan.info/Periodicals/LangCognNeurosci2018.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong> (2018). Scalar and ignorance inferences are both computed immediately upon encountering the sentential connective: The online processing of sentences with disjunction using the visual world paradigm. <em>Frontiers in Psychology, 9</em>. doi: 10.3389/fpsyg.2018.00061 <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00061/full"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p>Moscati, V., <strong>Zhan, L.</strong>, &amp; Zhou, P. (2017). Children’s on-line processing of epistemic modals. <em>Journal of Child Language, 44</em>(5), 1025-1040. doi: 10.1017/S0305000916000313 <a href="https://publications.likan.info/Periodicals/JChildLang2016.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong>, Crain, S., &amp; Zhou, P. (2015). The online processing of only if- and even if- conditional statements: Implications for mental models. <em>Journal of Cognitive Psychology, 26</em>(7), 367-379. doi: 10.1080/20445911.2015.1016527 <a href="https://publications.likan.info/Periodicals/JCognPsychol2015.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p>Zhou, P., Crain, S., &amp; <strong>Zhan, L.</strong> (2014). Grammatical aspect and event recognition in children’s online sentence comprehension. <em>Cognition, 133</em>(1), 262-276. doi: 10.1016/j.cognition.2014.06.018 <a href="http://publications.likan.info/Periodicals/Cognition2014.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p>Zhou, P., Crain, S., &amp; <strong>Zhan, L.</strong> (2012). Sometimes children are as good as adults: The pragmatic use of prosody in children’s on-line sentence processing. <em>Journal of Memory and Language, 67</em>(1), 149-164. doi: 10.1016/j.jml.2012.03.005 <a href="https://publications.likan.info/Periodicals/JMemLang2012.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p>Zhou, P., Su, Y., Crain, S., Gao, L., &amp; <strong>Zhan, L.</strong> (2012). Children’s use of phonological information in ambiguity resolution: a view from Mandarin Chinese. <em>Journal of Child Language, 39</em>(04), 687-730. doi: 10.1017/S0305000911000249 <a href="https://publications.likan.info/Periodicals/JChildLang2012.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Book chapters and conference proceedings</li>
</ol>
<ul>
<li><p><strong>Zhan, L.</strong> (2018). Magnetoencephalography (MEG) as a Technique for Imaging Brain Function and Dysfunction. In <em>Top 10 Contributions on Psychology</em> (Chapter 4, pp. 1-38). Telangana, India: Avid Science</p></li>
<li><p><strong>Zhan, L.</strong>, Crain, S., &amp; Zhou, P. (2013). The anticipatory e ects of focus operators: A visual- world paradigm eye-tracking study of “only if” and “even if” conditionals. In N. Goto, K. Otaki, A. Sato, &amp; K. Takita (Eds.), <em>Proceedings of GLOW in Asia IX 2012</em>. Mie University, Japan.</p></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Peer reviewed conference presentations</li>
</ol>
<ul>
<li><p><strong>Zhan, L.</strong>, &amp; Zhou, P. (2019, June). <em>Children differ from adults in interpreting disjunctions: Evidence from an eye-tracking study </em>. Poster session presented at Psycholinguistics in Iceland - Parsing and Prediction, University of Iceland, Reykjavík, Iceland. <a href="https://publications.likan.info/Talks/PIPP_Poster.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong> (2017, September). <em>Scalar implicature and ignorance inference are both locally computed: Evidence from the online processing of disjunctions using the visual world paradigm</em>. Paper presented at the Second High-level Forum on Cognitive Linguistics, University of International Business and Economics, Beijing, China. <a href="https://publications.likan.info/Talks/ZhanL2017UIBE.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong>, Crain, S., &amp; Zhou, P. (2013, November). <em>Going beyond the information that is perceived: The hypothetical property of if-conditionals in Mandarin Chinese</em>. Paper session presented at the Second International Conference on Psycholinguistics in China, Fuzhou, China.</p></li>
<li><p>Moscati, V., <strong>Zhan, L.</strong>, &amp; Zhou, P. (2013, November). <em>Reasoning on possibilities: An eye tracking study on modal knowledge</em>. Poster session presented at the 38th Annual Boston University Conference on Language Development, Boston University, MA.</p></li>
<li><p>Zhou, P., Crain, S., &amp; <strong>Zhan, L.</strong> (2013, November). <em>Anticipatory eye movements in children’s processing of grammatical aspect</em>. Poster session presented at the 38th Annual Boston University Conference on Language Development, Boston University, MA.</p></li>
<li><p><strong>Zhan, L.</strong>, Crain, S., &amp; Zhou, P. (2013, March). <em>The hypothetical property of “if”-statements: A visual- world paradigm eye-tracking study</em>. Poster session presented at CUNY2013: The 26th annual CUNY Sentence Processing Conference, Columbia, SC.</p></li>
<li><p><strong>Zhan, L.</strong>, Crain, S., &amp; Zhou, P. (2012, July). <em>The interpretation of conditionals</em>. Paper presented at the 7th International Conference on Thinking (ICT2012), Birkbeck/UCL, London, UK.</p></li>
<li><p>Zhou, P., Crain, S., &amp; <strong>Zhan, L.</strong> (2012, March). <em>Children’s pragmatic use of prosody in sentence processing</em>. Poster session presented at the 35th Generative Linguistics in the Old World (GLOW) Workshop: Production and Perception of Prosodically-Encoded Information Structure, University of Potsdam, Potsdam, Germany.</p></li>
<li><p><strong>Zhan, L.</strong>, Crain, S., &amp; Khlentzos, D. (2011, August). <em>The basic semantics of conditionals in natural language</em>. Paper presented at the Harvard-Australia Workshop on Language, Learning and Logic, Macquarie University, Sydney, Australia.</p></li>
<li><p>Zhou, P., Crain, S., Gao, L., &amp; <strong>Zhan, L.</strong> (2010, September). <em>The role of prosody in children’s focus identification</em>. Paper presented at the Generative Approaches to Language Acquisition - North America 4 (GALANA-4), Toronto, Canada.</p></li>
<li><p>Zhou, P., Su, Y., Crain, S., Gao, L., &amp; <strong>Zhan, L.</strong> (2010, August). <em>Children’s use of prosodic information in ambiguity resolution</em>. Paper presented at the 8th Conference of Generative Linguistics in the Old World Asia (GLOW-in-Asia 8), Beijing, China.</p></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Invited talks</li>
</ol>
<ul>
<li><p><strong>Zhan, L.</strong> (2018, December). <em>Sentential Reasoning and Sentential Connectives: Conditional, Disjunction, Negation, and Modality</em>. Inivted presentation given at the Workshop of Theoretical and Experimental Linguistics, Tsinghua University, Beijing, China. <a href="https://publications.likan.info/Talks/Sentential_Reasoning_Sentential_Connectives.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong> (2018, November). <em>Methods of Cognitive Neuroscience: Focus on Language</em>. Inivted presentation given at the Child Cognition Laboratory, Department of Foreign Languages and Literatures, Tsinghua University, Beijing, China. <a href="https://publications.likan.info/Talks/MethodsCognNeurosciLang2018NOV.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong> (2018, November). <em>Visual world paradigm: An eye-tracking technique to study the real time processing of spoken Language</em>. Inivted presentation given at the Center for Studies of Chinese as a Second Language, Beijing Language and Culture University, Beijing, China. <a href="https://publications.likan.info/Talks/Visual_World_Paradigm.pdf"><i class="far fa-file-pdf"> </i></a></p></li>
<li><p><strong>Zhan, L.</strong> (2018, October). <em>Experimental Builder: A What-You-See-Is-What-You-Get tool to build experiment scripts</em>. Inivted presentation given at the Center for Studies of Chinese as a Second Language, Beijing Language and Culture University, Beijing, China. <a href="https://publications.likan.info/Eyelink_Experiment_Builder_Training_Materials/"><i class="far fa-file-pdf"> </i></a></p></li>
</ul>
</div>
</div>
