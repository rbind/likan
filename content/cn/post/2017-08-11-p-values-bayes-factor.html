---
title: "统计的显著性水平"
author: "侃侃迩行"
date: '2017-08-11'
output:
  blogdown::html_page:
    toc: yes
    fig_height: 4
    fig_width: 8
  pdf_document:
    includes:
      in_header: header.tex
    latex_engine: xelatex
tags: [statistics, r]
---


<div id="TOC">
<ul>
<li><a href="#hypothesis-testing">1. 统计检验和显著性水平</a></li>
<li><a href="#bf">2. 显著性水平和贝叶斯因子</a></li>
<li><a href="#fpr">3. 显著性水平和假阳性率</a></li>
<li><a href="#power">4. 显著性水平和统计效力</a></li>
<li><a href="#summary">5. 总结</a></li>
<li><a href="#references">6. 参考文献</a></li>
</ul>
</div>

<p>提高某些领域研究可重复性的一个直接和简单的方法是提高假设检验的统计显著性水平。</p>
<div id="hypothesis-testing" class="section level1">
<h1>1. 统计检验和显著性水平</h1>
<p>统计检验中，研究者最终希望确定零假设 (<span class="math inline">\(H_{i,i=0}\)</span>) 和备则假设 (<span class="math inline">\(H_{i, i \neq 0}\)</span>) 中哪一个正确。由于这两种状态的不相容性，事实情况只有两种：要么是零假设正确；要么是其中一个备择假设如 <span class="math inline">\(H_1\)</span> 正确。让事情变得更为复杂的是，研究者用于判断哪个假设正确的证据并不来自于数据整体，而来自于整体数据的一部分，即一个样本。样本统计量对于总体参数来说始终存在一定偏差，即抽样误差。</p>
<p>第一、假如事实情况是零假设正确。假定零假设 (<span class="math inline">\(H_0\)</span>) 整体服从平均值为 <span class="math inline">\(\mu_0 = 0\)</span>, 标准差为 <span class="math inline">\(\sigma = 1\)</span> 的正态分布。即使在该零假设正确的前提下，由于抽样误差的原因，一个样本量为 <span class="math inline">\(n=1\)</span> 的随机样本的样本平均值 (<span class="math inline">\(\overline{X}_i\)</span>) 理论上来说可以是位于 <span class="math inline">\([-\infty, +\infty]\)</span> 之间的任何一个数。但是从概率上来讲，样本平均值在总体平均值 0 的位置出现的概率最高；一个位置离总体平均值越远，样本平均值在该位置出现的概率就越低。例如，一个样本平均值出现在 <span class="math inline">\(\pm 3\)</span> 位置上的概率就非常低了。 以样本平均值的大小为横坐标，该样本平均值出现的概率为纵坐标，可以画出如下样本平均值的概率密度分布图。</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_01-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><em>P</em>-值指在零假设正确的前提下，样本平均值 (<span class="math inline">\(\overline{X}_i\)</span>) 与某个观测值 (<span class="math inline">\(\overline{X}_\text{obs}\)</span>) 一样极端或者比观测值更极端的概率。如观测值 (<span class="math inline">\(\overline{X}_\text{obs} = -1\)</span>) 对应的 <em>P</em> 值为 <span class="math inline">\(P=0.16\)</span>。</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_02-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>如前所述，一个位置离总体平均值越远，样本平均值在该位置出现的概率就越低。当一个实际观测值 (<span class="math inline">\(\overline{X}_\text{obs}\)</span>) 离总体平均值足够远的时候，我们就有理由怀疑该样本不是来自零假设条件下的总体，而是来自于另外一个总体了。这个人为设定的<strong>足够远</strong>，即为 <span class="math inline">\(\alpha\)</span> 水平。心理学学家通常把该临界值定为 <span class="math inline">\(\alpha=0.05\)</span> (如下图)。如果观测值 (<span class="math inline">\(\overline{X}_\text{obs}\)</span>) 大于等于 1.96, 即 <span class="math inline">\(|\overline{X}_\text{obs}|\geq 1.96\)</span>，或其在分布中出现的概率小于等于 0.05, 研究者则断定该样本并不来自于零假设整体，而是来自某个备择假设整体。如图所示，<span class="math inline">\(\alpha\)</span> 水平又等价于当零假设实际上正确，但研究者拒绝零假设的概率，即 <strong>I 类错误水平</strong>。</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_03-1.png" width="768" style="display: block; margin: auto;" /> 第二、假设事实情况是零假设 (<span class="math inline">\(H_0\)</span>) 错误，备择假设 (<span class="math inline">\(H_1\)</span>) 正确。同时假定零假设 (<span class="math inline">\(H_0\)</span>) 和备择假设 (<span class="math inline">\(H_1\)</span>) 间效应值大小为 <span class="math inline">\(\text{Cohen&#39;s D} = 4\)</span>，即备择假设 (<span class="math inline">\(H_1\)</span>) 整体服从平均值为 <span class="math inline">\(\mu_0 = 4\)</span>, 标准差为 <span class="math inline">\(\sigma = 1\)</span> 的正态分布。如果依然把显著性水平定为 <span class="math inline">\(\alpha=0.05\)</span>，即当 <span class="math inline">\(P \leq 0.05\)</span> 或观测值 <span class="math inline">\(\overline{X}_{obs} \geq 1.96\)</span> 时，拒绝零假设。 因为实际情况是备择假设 (<span class="math inline">\(H_1\)</span>) 正确 (如下图)，此时样本平均值 (<span class="math inline">\(\overline{X}_i\)</span>) 有 <span class="math inline">\(1-\beta=0.98\)</span> 的可能性位于临界值 1.96 的右侧，另有 <span class="math inline">\(\beta = 0.021\)</span> 的可能性位于临界值的左侧。所以当 <span class="math inline">\(\overline{X}_{obs} \geq 1.96\)</span> 时，如果我们拒绝零假设(<span class="math inline">\(H_0\)</span>)，接受备则假设 <span class="math inline">\(H_1\)</span>，那么我们的判断正确的概率是 <span class="math inline">\(1-\beta = 0.98\)</span>。正确拒绝零假设的概率，<span class="math inline">\(1-\beta\)</span> 又被称作统计效力 (statistical power)。因为在备择假设 (<span class="math inline">\(H_1\)</span>) 正确的前提下，样本平均值 (<span class="math inline">\(\overline{X}_i\)</span>) 仍有 <span class="math inline">\(\beta = 0.021\)</span> 的可能性位于临界值的左侧。所以当观测值位于临界值左侧 <span class="math inline">\(\overline{X}_{obs} &lt; 1.96\)</span>，我们的结论是无法拒绝零假设时，我们有 <span class="math inline">\(\beta = 0.021\)</span> 的可能性是错的。此时研究者犯的是 <strong>II 类错误</strong>，即实际上零假设 <span class="math inline">\(H_0\)</span> 错误，备择假设 <span class="math inline">\(H_1\)</span> 正确，但根据观测数据研究者无法拒绝零假设的情况。如图所示，II 类错误的概率是 <span class="math inline">\(\beta\)</span>。</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_04-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>上述四种情况可以总结为下面这个表格：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center"><span class="math inline">\(H_0\)</span></th>
<th align="center"><span class="math inline">\(H_1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>没有拒绝零假设</td>
<td align="center">正确拒斥（<span class="math inline">\(1-\alpha\)</span>）</td>
<td align="center">漏报（II类错误，<span class="math inline">\(\beta\)</span>值）</td>
</tr>
<tr class="even">
<td>拒绝零假设</td>
<td align="center">虚报（I类错误，<span class="math inline">\(\alpha\)</span>值）</td>
<td align="center">击中（统计效力，<span class="math inline">\(1-\beta\)</span>）</td>
</tr>
</tbody>
</table>
<p>以及下面这个图：</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_05-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="bf" class="section level1">
<h1>2. 显著性水平和贝叶斯因子</h1>
<p>如前所述，<em>P</em> 值指在零假设 (<span class="math inline">\(H_0\)</span>) 正确的条件下，研究者记录到某个观测值 (<span class="math inline">\(\overline{X}_{obs}\)</span>) 的概率，即 <span class="math inline">\(Pr(\overline{X}_{obs}|H_0)\)</span>。而研究者关心的是记录到该观测值时零假设或备择假设正确与否的概率，即<span class="math inline">\(Pr(H_0|\overline{X}_{obs})\)</span> 或 <span class="math inline">\(Pr(H_1|\overline{X}_{obs})\)</span> 概率的大小。大多数情况下，研究者通常无法以一种二元论的方式去确定零假设还是备择假设正确，而只能从概率上哪讲哪个假设正确的可能性更大。判断哪个可能性更大的更直接证据来自于备择假设 <span class="math inline">\(H_1\)</span> 和零假设 <span class="math inline">\(H_0\)</span> 发生概率的比率 (Odds)。如下图所示，根据贝叶斯原则，在观测值 <span class="math inline">\(\overline{X}_{obs}\)</span> 条件下，备择假设和零假设发生率之比受<strong>贝叶斯因子</strong> (Bayes factor, <strong>BF</strong>) 和<strong>先验概率</strong> (prior odds) 两个因素的共同影响。</p>
<p><span class="math display">\[
\frac{\text{Pr }(H_1|\overline{X}_{obs})}{\text{Pr }(H_0|\overline{X}_{obs})}=
\frac{\text{Pr }(\overline{X}_{obs}|H_1)}{\text{Pr }(\overline{X}_{obs}|H_0)}\times
\frac{\text{Pr }(H_1)}{\text{Pr }(H_0)}=
BF \times (\text{prior odds})
\]</span></p>
<p>第一，关于备择假设和零假设发生概率之比的<strong>先验知识</strong> (prior odds) 通常来源于研究者的前期假设、相关领域科学研究的共识、或同领域相似研究问题的其他研究。通常认为，心理学研究和癌症临床研究中，备择假设和零假设的先验比率约为 <strong>1:10</strong>。而在前临床的生物医学研究 (preclinical biomedical reaearch) 领域，该先验比率会更低。</p>
<p>第二、 <strong>贝叶斯因子</strong>来源于观测数据，贝叶斯因子的大小表明了证据的强度。贝叶斯因子越大，观测数据越有能力支持备择假设假设。按照 Kass 和 Raftery (1995) 的观点，贝叶斯因子的大小和证据强度 (strength of evidence) 存在以下关系：</p>
<table>
<thead>
<tr class="header">
<th align="center">贝叶斯因子大小</th>
<th align="center">否定零假设的证据强度</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1-3.2</td>
<td align="center">不值一提</td>
</tr>
<tr class="even">
<td align="center">3.2-10</td>
<td align="center">显著的 (Substantial)</td>
</tr>
<tr class="odd">
<td align="center">10-100</td>
<td align="center">强 (Strong)</td>
</tr>
<tr class="even">
<td align="center">&gt;100</td>
<td align="center">确定的 (Decisive)</td>
</tr>
</tbody>
</table>
<p>贝叶斯因子和 <em>P</em>-值之间的关系受备择假设的影响。要确定贝叶斯因子和 <em>P</em>-值之间的关系，首先要确定备择假设 <span class="math inline">\(\overline{H}_{i,i\neq0}\)</span> 的分布特征。确定备择假设的方法不同，计算出的贝叶斯因子和 <em>P</em>-值的关系也不同。如果我们假定备择假设和零假设条件下整体分布的形状一致，那么确定备择假设的分布特征就是确定其整体平均值 <span class="math inline">\(\mu_1\)</span>。</p>
<ul>
<li>第一种方法利用显著性检验中的<strong>统计效力</strong>大小确定备择假设的整体平均值。例如，备择假设整体平均值 <span class="math inline">\(\mu_1\)</span> 的大小必须让被则假设满足其统计效力为 75%。根据统计效力大小确定备择假设后，观察到的 <em>P</em>-值大小和贝叶斯因子大小之间的关系叫做 <strong>效力曲线</strong> (power)。</li>
</ul>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_06-1.png" width="768" style="display: block; margin: auto;" /></p>
<ul>
<li>第二种方法是通过显著性水平来确定备择假设的整体平均值的。Johnson (2013) 认为备择假设的整体平均值应该设定在 <span class="math inline">\(\alpha／2 = 0.0025\)</span> 处。这种方法叫做<strong>均匀最大功效贝叶斯检验</strong> (Uniformly Most Powerful Bayesian Test, UMPBT)。在我们的例子中，零假设为真时 <span class="math inline">\(\alpha／2 = 0.0025\)</span> 对应的 <span class="math inline">\(\overline{X}_{obs}=\)</span> 2.81，所以备择假设的整体平均值为 <span class="math inline">\(\mu_1=\)</span> 2.81。因为当备择假设的整体平均值为 <span class="math inline">\(\mu_1=\)</span> 2.81 时，显著性检验的统计效力为 <span class="math inline">\(1-\beta=0.80\)</span>，所以该方法确定的备择假设与第一种方法中把统计效力设定为 <span class="math inline">\(80\%\)</span> 时的出来的 <span class="math inline">\(P\)</span>-值和贝叶斯因子之间的关系是一样的。</li>
</ul>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_07-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>后两种方法没有试图找到一个特定备择假设，而是在假定备择假设具有某种特点时，去描述 <em>P</em>-值和贝叶斯因子的关系。</p>
<ul>
<li>第三种方法认为如果备择假设 <span class="math inline">\(H_{i}\)</span> 的整体平均值 <span class="math inline">\(\mu_i\)</span> 以零假设 <span class="math inline">\(H_{i, i=0}\)</span> 的整体平均值 <span class="math inline">\(\mu_0\)</span> 为中心的对称分布时，那么贝叶斯因子的上限将不超过 <span class="math inline">\(BF = 1/(2\times \exp(\frac{1}{2}t^2))\)</span>，此处 <span class="math inline">\(t\)</span> 指 I 类错误的大小。此种方法被称作 <strong>似然值比率范围</strong> (likelihood ratio bound) (Berger, &amp; Sellke, 1987)</li>
<li>第四种方法认为当备择假设 <span class="math inline">\(H_{i}\)</span> 的整体平均值 <span class="math inline">\(\mu_i\)</span> 是一个以零假设 <span class="math inline">\(H_{i, i=0}\)</span> 的整体平均值 <span class="math inline">\(\mu_0\)</span> 为众数的单峰分布 (unimodal)，并满足某些限制条件时，贝叶斯因子的上限将不超过 <span class="math inline">\(BF=1/(-\exp(1) \cdot p \ \cdot \ln(p))\)</span>，<span class="math inline">\(p\)</span> 即为 <span class="math inline">\(p\)</span>-值的大小。此方法被称作<strong>局部 <span class="math inline">\(H_1\)</span> 范围</strong> (Local-<span class="math inline">\(H_1\)</span> Bound) (Sellke, Bayarri, &amp; Berger, 2001)</li>
</ul>
<p>用上述四种方法确定备择假设或者假定备择假设具有某种特征后，<em>P</em>-值和贝叶斯因子的关系可以用下图表示(Benjamin et al., 2017)：</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_2_01-1.png" width="768" style="display: block; margin: auto;" /> 如上图所示，显著性水平为 <span class="math inline">\(P &lt; .05\)</span> 的双尾检验所对应的贝叶斯因子仅为 <span class="math inline">\(2.5 - 3.4\)</span>。根据前面的描述，此时否定零假设的证据是非常弱的。如果我们把研究的先验概率设定为 <span class="math inline">\(1:10\)</span>，此时备择假设发生的可能性仅为零假设发生可能性的三分之一，即 <span class="math inline">\(\frac{1}{3} = 3.4 \times \frac{1}{10}\)</span>。而当我们把显著性水平设定为 <span class="math inline">\(p &lt; .005\)</span> 的水平上时，贝叶斯因子就增加到了 <span class="math inline">\(13.80-25.70\)</span>。根据前述标准，此时证据力度是很强的。在同样的先验概率下，备择假设和零假设的比率增加到了 <span class="math inline">\(2.57\)</span>。</p>
</div>
<div id="fpr" class="section level1">
<h1>3. 显著性水平和假阳性率</h1>
<p>在贝叶斯框架下，<em>P</em>-值的一个对应替代方案是<strong>假阳性率</strong>（false positive rate，FPR)。错误发现率指在所有零假设被拒绝的情景中，零假设实际上为真的概率。假设一项研究中，零假设 (<span class="math inline">\(H_0\)</span>) 为真的概率为 <span class="math inline">\(\phi\)</span>，备择假设 (<span class="math inline">\(H_i\)</span>) 为真概率则为 <span class="math inline">\(1-\phi\)</span>。如果把假设检验的临界值设定为 <span class="math inline">\(\alpha\)</span>， 即当 <span class="math inline">\(P &lt; \alpha\)</span> 时拒绝零假设 (<span class="math inline">\(H_0\)</span>)。因为零假设发生的概率是 <span class="math inline">\(\phi\)</span>，那么研究者错误拒绝零假设的概率为 <span class="math inline">\(\alpha\phi\)</span>。另外如果该假设检验的统计效力为 <span class="math inline">\(1-\beta\)</span>，那么研究者正确拒绝零假设的概率为 <span class="math inline">\((1-\beta)(1-\phi)\)</span>。 此时错误发现率可以表示为错误决绝零假设的概率与所有拒绝零假设的概率的比率，如下图：</p>
<p><span class="math display">\[
\text{false positive rate} \approx
\frac
{\alpha\phi}
{\alpha\phi + (1-\beta)(1-\alpha)}
\]</span></p>
<p>如上面的公式所示，假阳性率同时受显著性水平、先验概率和统计效力的共同影响。在选取了三个先验概率水平 <span class="math inline">\(1:40\)</span>、<span class="math inline">\(1:10\)</span> 和 <span class="math inline">\(1:5\)</span>，两个显著性水平 <span class="math inline">\(P &lt;.05\)</span> 和 <span class="math inline">\(p &lt;.005\)</span> 后，我们可以看到假阳性率和统计效力存在下图所示的关系：</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_3_01-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>如上图所示，低统计效力加上低显著性水平 <span class="math inline">\(\alpha = 0.05\)</span> 将产生高比率的假阳性率。如果显著性水平设置为 <span class="math inline">\(P &lt; 0.05\)</span>，先验概率设定为 <em>1:10</em>，那么无论统计效力处于什么水平，该分析的假阳性率将<strong>不低于 33%</strong>。心理学及许多科学研究的一个事实是统计效力都比较低。而如果把显著性水提高到 <em>0.005</em>，则在绝大部分统计效力范围内，假阳性率可降到 <span class="math inline">\(5\%\)</span> 之下。</p>
</div>
<div id="power" class="section level1">
<h1>4. 显著性水平和统计效力</h1>
<p>提高统计显著性水平的缺点也是显而易见的，即提高统计的显著性水平将显著降低假设检验的统计效力、提高 II 类错误的概率。如下图所示，在 <span class="math inline">\(\alpha=0.05\)</span> 的显著性水平下，该显著性检验的统计效力为 <span class="math inline">\(1-\beta=0.80\)</span> 。 <img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_08-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>但当我们把统计显著性提高到 <span class="math inline">\(\alpha=0.005\)</span> 时，该检验的统计效力就降低到了 <span class="math inline">\(1-\beta=0.50\)</span>。</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_09-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>此时，如果想保持原来的统计效力水平，研究者就需要提高研究的样本量（实际应用中，这将增加项目的研究成本）。如下图所示，如果我们把样本量增加 70%，检验的统计效力将恢复到 <span class="math inline">\(1-\beta=0.80\)</span> 的水平。</p>
<p><img src="/cn/post/2017-08-11-p-values-bayes-factor_files/figure-html/Figure_1_10-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="summary" class="section level1">
<h1>5. 总结</h1>
<p>如前所述，提高假设检验中的统计显著性水平能显著提高统计检验的贝叶斯因子水平、显著降低统计检验的假阳性率。在实践中，提高统计显著性水平也能显著提高科学研究的可重复性 (Benjamin et al., 2017)。正是基于上述原因，目前有 72 为统计学家联名发文希望在传统上使用两个标准差 (<span class="math inline">\(\alpha = .05\)</span>) 作为显著性水平的研究领域应该把显著性水平提高到三个标准差 (<span class="math inline">\(\alpha = .005\)</span>) (Benjamin et al., 2017)。</p>
<p>在某些先验概率非常低的探索性研究领域，研究者需要远比 0.005 更为严苛的显著性水平。如通常认为基因和高能物理研究领域的显著性水平应该符合五个标准差原则 (5-sigma)，即显著性水平大约为 <span class="math inline">\(P &lt; 3\times 10^{-7}\)</span>。</p>
<p>提高统计的显著性水平并不是解决研究可重复性问题的唯一方法。其他可能的解决方案包括选择更为合适的统计方法，如模型比较和贝叶斯学习等、更周到的实验设计、预实验等等。当然，改变 <em>P</em>-值的显著性水平最为直接和最为简单的方法。</p>
</div>
<div id="references" class="section level1">
<h1>6. 参考文献</h1>
<p>Altman, N., &amp; Krzywinski, M. (2017). Points of Significance: Interpreting P values. <em>Nature Methods, 14</em>(3), 213-214. <a href="doi:10.1038/nmeth.4210" class="uri">doi:10.1038/nmeth.4210</a></p>
<p>Benjamin, D. J., et al.,. (2017). Redefine Statistical Significance. <em>Nature Human Behavior</em>. <a href="doi:10.1038/s41562-017-0189-z" class="uri">doi:10.1038/s41562-017-0189-z</a></p>
<p>Berger, J. O., &amp; Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and Evidence. <em>Journal of the American Statistical Association, 82</em>(397), 112-122.</p>
<p>Chawla, D. S. (2017). P-value shake-up proposed. <em>Nature, 548</em>, 16-17. <a href="doi:10.1038/nature.2017.22375" class="uri">doi:10.1038/nature.2017.22375</a></p>
<p>Johnson, V. E. (2013). Revised standards for statistical evidence. <em>Proceedings of the National Academy of Sciences of the United States of America, 110</em>(48), 19313-19317. <a href="doi:10.1073/pnas.1313476110" class="uri">doi:10.1073/pnas.1313476110</a></p>
<p>Kass, R. E., &amp; Raftery, A. E. (1995). Bayes Factors. <em>Journal of the American Statistical Association, 90</em>(430), 773-795. <a href="doi:10.1080/01621459.1995.10476572" class="uri">doi:10.1080/01621459.1995.10476572</a></p>
<p>Nuzzo, B. (2014). Statistical errors. <em>Nature, 506</em>, 150-152. <a href="doi:http://doi.org/10.1038/506150a" class="uri">doi:http://doi.org/10.1038/506150a</a></p>
<p>Sellke, T., Bayarri, M. J., &amp; Berger, J. O. (2001). Calibration of p Values for Testing Precise Null Hypotheses. <em>The American Statistician, 55</em>(1), 62-71. <a href="doi:10.1198/000313001300339950" class="uri">doi:10.1198/000313001300339950</a></p>
<p>Wasserstein, R. L., &amp; Lazar, N. A. (2016). The ASA‘s Statement on p-Values: Context, Process, and Purpose. <em>The American Statistician, 70</em>(2), 129-133. <a href="doi:10.1080/00031305.2016.1154108" class="uri">doi:10.1080/00031305.2016.1154108</a></p>
</div>
